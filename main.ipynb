{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.models as md\n",
    "import lign.utils as utl\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "tm_now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "\n",
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"CIFAR\" #<<<<<\n",
    "\n",
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = utl.load.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/datasets/cifar100_train.lign\")\n",
    "\n",
    "validate = utl.load.cifar_to_lign(\"data/datasets/CIFAR100\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MNIST\" #<<<<<\n",
    "\n",
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = utl.load.mnist_to_lign(\"data/datasets/MNIST\", transforms = trans)\n",
    "dataset.save(\"data/datasets/mnist_train.lign\")\n",
    "\n",
    "validate = utl.load.mnist_to_lign(\"data/datasets/MNIST\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/mnist_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"CIFAR\" #<<<<<\n",
    "\n",
    "dataset = lg.graph.GraphDataset(\"data/datasets/cifar100_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MNIST\" #<<<<<\n",
    "\n",
    "dataset = lg.graph.GraphDataset(\"data/datasets/mnist_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/mnist_test.lign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if th.cuda.is_available():\n",
    "    device = th.device(\"cuda\")\n",
    "    th.cuda.empty_cache()\n",
    "else:\n",
    "    device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs): ## adds up neighbors' data before executing post_mod (pre_mod happens before)\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neigh\n",
    "    return out\n",
    "\n",
    "class ADDON(nn.Module): ## tempory layer for training\n",
    "    def __init__(self, in_fea, out_fea, device = 'cuda'):\n",
    "        super(ADDON, self).__init__()\n",
    "        self.addon = lg.layers.ADDON(in_fea, out_fea, device=device)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = F.log_softmax(self.addon(g, features), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "* LAMBDA: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating pairwise loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model initially in the supervised method to learn pairwise mapping\n",
    "* LABELS: list of all the labels that model comes across. Labels can be appended at any time. The order of labels is initially randomized\n",
    "* SUBGRAPH_SIZE: represent the number of nodes processed at once. The models don't have batches. This is the closest thing to it\n",
    "* AMP_ENABLE: toggle to enable mixed precission training\n",
    "* EPOCHS: Loops executed during training\n",
    "* LR: Learning rate\n",
    "* RETRAIN_PER: period between retraining based on number of labels seen. format: (offset, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.5\n",
    "DIST_VEC_SIZE = 2 #128\n",
    "INIT_NUM_LAB = 4\n",
    "LABELS = np.arange(10)\n",
    "SUBGRPAH_SIZE = 500\n",
    "AMP_ENABLE = True\n",
    "EPOCHS = 150\n",
    "LR = 1e-3\n",
    "RETRAIN_PER = {\n",
    "    \"superv\": (5, 2), # (offset, frequency)\n",
    "    #\"semi\": (0, 15)\n",
    "}\n",
    "\n",
    "#np.random.shuffle(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Models\n",
    "### LIGN\n",
    "\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIGN_MNIST(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_MNIST, self).__init__()\n",
    "        self.gcn1 = lg.layers.GCN(nn.Conv2d(1, 32, 3, 1))\n",
    "        self.gcn2 = lg.layers.GCN(nn.Conv2d(32, 64, 3, 1))\n",
    "        self.gcn3 = lg.layers.GCN(nn.Linear(9216, out_feats))\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.gcn1(g, features))\n",
    "        x = F.relu(self.gcn2(g, x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = th.flatten(self.drop1(x), 1)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "\n",
    "        return self.drop2(x)\n",
    "\n",
    "model = LIGN_MNIST(DIST_VEC_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt\n",
    "accuracy = []\n",
    "log = []\n",
    "num_of_labels = len(LABELS)\n",
    "opt = th.optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = GradScaler() if AMP_ENABLE else None\n",
    "addon = ADDON(DIST_VEC_SIZE, INIT_NUM_LAB, device).to(device)\n",
    "\n",
    "retrain_superv = lambda x: (x + RETRAIN_PER[\"superv\"][0])%RETRAIN_PER[\"superv\"][1] == 0\n",
    "#retrain_semi = lambda x: (x + RETRAIN_PER[\"semi\"][0])%RETRAIN_PER[\"semi\"][1] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = th.load('data/models/LIGN_training_cool_time.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "opt.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "if AMP_ENABLE:\n",
    "    scaler.load_state_dict(checkpoint['scaler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction: \n",
      "tensor([2, 3, 0,  ..., 1, 2, 1], device='cuda:0')\n",
      "True values: \n",
      "tensor([2, 1, 0,  ..., 1, 2, 3], device='cuda:0')\n",
      "Vector output: \n",
      "tensor([[0.0000, 0.2880],\n",
      "        [0.0000, 0.0669],\n",
      "        [0.0800, 0.2165],\n",
      "        ...,\n",
      "        [0.0000, 0.1180],\n",
      "        [0.0448, 0.3269],\n",
      "        [0.0287, 0.2106]], device='cuda:0')\n",
      "33.26918450805869\n"
     ]
    }
   ],
   "source": [
    "acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:INIT_NUM_LAB], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:INIT_NUM_LAB], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "\n",
    "for num_labels in range(INIT_NUM_LAB, num_of_labels + 1):\n",
    "    \"\"\"if retrain_semi(num_labels):\n",
    "        lg.train.semi_superv(model, opt, dataset, \"x\", \"labels\", DIST_VEC_SIZE, LABELS[:num_labels], LAMBDA, (device, scaler), addon = ADDON, subgraph_size=SUBGRPAH_SIZE, epochs=EPOCHS, cluster=(utl.clustering.NN(), 5))\"\"\"\n",
    "\n",
    "    if retrain_superv(num_labels):\n",
    "        addon.addon.update_size(num_labels)\n",
    "        lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:num_labels], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "    \n",
    "    acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:num_labels], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device)\n",
    "\n",
    "    accuracy.append(acc)\n",
    "    log.append(\"Label: {}/{} -- Accuracy: {}% -- Semisurpervised Retraining: {} -- Surpervised Retraining: {}\".format(num_labels, num_of_labels, round(acc, 2), 5, retrain_superv(num_labels)))\n",
    "    print(log[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = str(tm_now()).replace(\":\", \"-\").replace(\".\", \"\").replace(\" \", \"_\")\n",
    "filename = \"LIGN_\" + dataset_name + \"_training_\"+time\n",
    "\n",
    "## Save metrics\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"log\": log\n",
    "}\n",
    "utl.io.json(metrics, \"data/metrics/\"+filename+\".json\")\n",
    "\n",
    "## Save hyperparameters\n",
    "para = {\n",
    "    \"LAMBDA\": LAMBDA,\n",
    "    \"DIST_VEC_SIZE\": DIST_VEC_SIZE,\n",
    "    \"INIT_NUM_LAB\": INIT_NUM_LAB,\n",
    "    \"LABELS\": LABELS.tolist(),\n",
    "    \"SUBGRPAH_SIZE\": SUBGRPAH_SIZE,\n",
    "    \"AMP_ENABLE\": AMP_ENABLE,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"LR\": LR,\n",
    "    \"RETRAIN_PER\": RETRAIN_PER\n",
    "}\n",
    "\n",
    "utl.io.json(para, \"data/parameters/\"+filename+\".json\")\n",
    "\n",
    "## Save model\n",
    "check = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": opt.state_dict()\n",
    "}\n",
    "if AMP_ENABLE:\n",
    "    check[\"scaler\"] = scaler.state_dict()\n",
    "\n",
    "th.save(check, \"data/models/\"+filename+\".pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## View\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(LAMBDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}