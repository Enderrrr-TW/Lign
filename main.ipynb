{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "***_ Training can only be done with a device that has cuda and/or tensor cores_**\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.model as md\n",
    "import lign.utils as utl\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "The data needs to formatted and set up for lign. GraphDatabase instaces are needed to load graphs into the model and track their node\n",
    "\n",
    "### Create Dataset\n",
    "***_ Only run one of the following cells within \"Create Dataset\"_**\n",
    "\n",
    "***_ Also, either run \"Create Dataset\" or \"Load Dataset\". Not both _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/cifar100_train.lign\")\n",
    "\n",
    "validate = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", train=False, transforms = trans)\n",
    "validate.save(\"data/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "***_ Only run one of the following cells within \"Load Dataset\"_**\n",
    "\n",
    "***_ Also, either run \"Create Dataset\" or \"Load Dataset\". Not both _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lg.graph.GraphDataset(\"data/cifar100_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs\n",
    "Searches for nvidia GPUs in order to speed up training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs\n",
    "Possible functions and NNs used throughout the code to apply changes to the graph's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs):\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neighs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "*_ LABELS needs to be adjusted to reflect the total number of labels in the model _\n",
    "* LAMBDA: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model initially in the supervised method to learn pairwise mapping\n",
    "* LABELS: track all the labels that model comes across. The order will be randomized\n",
    "* SUBGRAPH_SIZE: represent the number of nodes processed at once. The models don't have batches. This is the closest thing to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.0001\n",
    "DIST_VEC_SIZE = 3 # 3 was picked so it can be drawn into the 3d graph\n",
    "INIT_NUM_LAB = 10\n",
    "LABELS = np.arange(100)\n",
    "SUBGRPAH_SIZE = 200\n",
    "\n",
    "np.random.shuffle(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model\n",
    "***_ Either run LIGN or R-LIGN. Not both _** \n",
    "### LIGN\n",
    "\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIGN_cnn(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_cnn, self).__init__()\n",
    "        self.gcn1 = md.layers.GCN(module_post = nn.Conv2d(3, 6, 5))\n",
    "        self.gcn2 = md.layers.GCN(module_post = nn.Conv2d(6, 16, 5))\n",
    "        self.gcn3 = md.layers.GCN(module_post = nn.Linear(16 * 5 * 5, 150))\n",
    "        self.gcn4 = md.layers.GCN(module_post = nn.Linear(150, 84))\n",
    "        self.gcn5 = md.layers.GCN(module_post = nn.Linear(84, out_feats))\n",
    "        self.pool = md.layers.GCN(module_post = nn.MaxPool2d(2, 2))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.pool(F.relu(self.gcn1(g, features)))\n",
    "        x = self.pool(F.relu(self.gcn2(g, x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "        x = F.relu(self.gcn4(g, x))\n",
    "        \n",
    "        return th.tanh(self.gcn5(g, x))\n",
    "\n",
    "model = LIGN_cnn(DIST_VEC_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LIGN\n",
    "[R]ecurrent [L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (R-LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.set_data(\"h\", )\n",
    "#dataset.set_data(\"c\", )\n",
    "####\n",
    "# model = R_LIGN(DIST_VEC_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Pre-Trained Models\n",
    "### LIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt\n",
    "accuracy = []\n",
    "num_of_labels = len(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.train.superv(model, dataset, LABELS[:INIT_NUM_LAB])\n",
    "\n",
    "for num_labels in range(INIT_NUM_LAB, num_of_labels + 1):\n",
    "\n",
    "    retrain_track = num_labels%30\n",
    "    if retrain_track == 15:\n",
    "        lg.train.unsuperv(model, dataset, \"x\", \"labels\", DIST_VEC_SIZE, LAMBDA, LABELS[:num_labels], subgraph_size=SUBGRPAH_SIZE)\n",
    "    elif retrain_track == 0:\n",
    "        lg.train.superv(model, dataset, \"x\", \"labels\", DIST_VEC_SIZE, LAMBDA, LABELS[:num_labels], subgraph_size=SUBGRPAH_SIZE)\n",
    "    \n",
    "    #acc = lg.test.accuracy(model, validate, cluster, LABELS[:num_labels])\n",
    "    accuracy.append()\n",
    "    print(\"Label: {num_labels}/{num_of_labels} | Accuracy: {acc} | Unsurpervised Retraining: {retrain_track}:15 | \" +\n",
    "    \"Surpervised Retraining: {retrain_track}:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## View\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}