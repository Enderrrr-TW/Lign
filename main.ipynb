{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.model as md\n",
    "import lign.utils.io as io\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "The data needs to formatted and set up for lign. A GraphDatabase class is needed to load graphs into the model and track the node. **_Only needs to be ran once_**\n",
    "\n",
    "### Create Dataset\n",
    "*_ Only run one of the following cells_ \n",
    "\n",
    "*_ Either run \"Create Dataset\" or \"Load Dataset\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "dataset = io.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/cifar100.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "*_ Only run one of the following cells_\n",
    "\n",
    "*_ Either run \"Create Dataset\" or \"Load Dataset\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lg.graph.GraphDataset(\"data/cifar100.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs\n",
    "Searches for nvidia GPUs in order to speed up training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs\n",
    "Functions and possible NNs used throughout the code to apply changes to the graph's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs):\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neighs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "* Lambda: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model inially in a supervised methods to learn feature mapping\n",
    "* LABELS: track all the labels that are inputed into the models. The order will be randomized\n",
    "* SUBGRAPH_SIZE: represent how many nodes to process at once. lign doesn't have batches. This is the closest thing to it\n",
    "\n",
    "_ LABELS needs to be adjusted to reflect the total number of labels in the model. LABELS is used to track which labels have been given to the the model _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda = 0.0001\n",
    "DIST_VEC_SIZE = 3\n",
    "INIT_NUM_LAB = 10\n",
    "LABELS = np.arange(100)\n",
    "SUBGRPAH_SIZE = 500\n",
    "\n",
    "\n",
    "np.random.shuffle(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model\n",
    "### LIGN\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIGN_cnn(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_cnn, self).__init__()\n",
    "        self.gcn1 = md.layers.GCN(func = sum_neighs_data, module_post = nn.Conv2d(3, 6, 5))\n",
    "        self.gcn2 = md.layers.GCN(func = sum_neighs_data, module_post = nn.Conv2d(6, 16, 5))\n",
    "        self.gcn3 = md.layers.GCN(func = sum_neighs_data, module_post = nn.Linear(16 * 5 * 5, 150))\n",
    "        self.gcn4 = md.layers.GCN(func = sum_neighs_data, module_post = nn.Linear(150, 84))\n",
    "        self.gcn5 = md.layers.GCN(func = sum_neighs_data, module_post = nn.Linear(84, out_feats))\n",
    "        self.pool = md.layers.GCN(func = sum_neighs_data, module_post = nn.MaxPool2d(2, 2))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.pool(F.relu(self.gcn1(g, features)))\n",
    "        x = self.pool(F.relu(self.gcn2(g, x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "        x = F.relu(self.gcn4(g, x))\n",
    "        \n",
    "        return th.tanh(self.gcn5(g, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LIGN\n",
    "[R]ecurrent [L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (R-LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.set_data(\"h\", )\n",
    "#dataset.set_data(\"c\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}