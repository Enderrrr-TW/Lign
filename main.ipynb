{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.models as md\n",
    "import lign.utils as utl\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "tm_now = datetime.datetime.now\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "The data needs to formatted and set up for lign. GraphDatabase instaces are needed to load graphs into the model and track their node\n",
    "\n",
    "### Create Dataset\n",
    "***_ Only run one of the following cells within \"Create Dataset\"_**\n",
    "\n",
    "***_ Also, either run \"Create Dataset\" or \"Load Dataset\". Not both _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/datasets/cifar100_train.lign\")\n",
    "\n",
    "validate = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "***_ Only run one of the following cells within \"Load Dataset\"_**\n",
    "\n",
    "***_ Also, either run \"Create Dataset\" or \"Load Dataset\". Not both _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lg.graph.GraphDataset(\"data/datasets/cifar100_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs\n",
    "Searches for nvidia GPUs in order to speed up training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs\n",
    "Possible functions and NNs used throughout the code to apply changes to the graph's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs):\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neighs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "*_ LABELS needs to be adjusted to reflect the total number of labels in the model _\n",
    "* LAMBDA: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating pairwise loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model initially in the supervised method to learn pairwise mapping\n",
    "* LABELS: track all the labels that model comes across. The order will be randomized\n",
    "* SUBGRAPH_SIZE: represent the number of nodes processed at once. The models don't have batches. This is the closest thing to it\n",
    "* AMP_ENABLE: to enable mixed precission training\n",
    "* LR: Learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.0001\n",
    "DIST_VEC_SIZE = 3 # 3 was picked so the graph can be drawn in a 3d grid\n",
    "INIT_NUM_LAB = 10\n",
    "LABELS = np.arange(100)\n",
    "SUBGRPAH_SIZE = 200\n",
    "AMP_ENABLE = True\n",
    "LR = 1e-3\n",
    "\n",
    "np.random.shuffle(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model\n",
    "***_ Either run LIGN or R-LIGN. Not both _** \n",
    "### LIGN\n",
    "\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'lign.models' has no attribute 'layers'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f87a4c77a1ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLIGN_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIST_VEC_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-f87a4c77a1ba>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, out_feats)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLIGN_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcn3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lign.models' has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "class LIGN_cnn(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_cnn, self).__init__()\n",
    "        self.gcn1 = md.layers.GCN(module_post = nn.Conv2d(3, 6, 5))\n",
    "        self.gcn2 = md.layers.GCN(module_post = nn.Conv2d(6, 16, 5))\n",
    "        self.gcn3 = md.layers.GCN(module_post = nn.Linear(16 * 5 * 5, 150))\n",
    "        self.gcn4 = md.layers.GCN(module_post = nn.Linear(150, 84))\n",
    "        self.gcn5 = md.layers.GCN(module_post = nn.Linear(84, out_feats))\n",
    "        self.pool = md.layers.GCN(module_post = nn.MaxPool2d(2, 2))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.pool(F.relu(self.gcn1(g, features)))\n",
    "        x = self.pool(F.relu(self.gcn2(g, x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "        x = F.relu(self.gcn4(g, x))\n",
    "        \n",
    "        return th.tanh(self.gcn5(g, x))\n",
    "\n",
    "model = LIGN_cnn(DIST_VEC_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LIGN\n",
    "[R]ecurrent [L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (R-LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.set_data(\"h\", )\n",
    "#dataset.set_data(\"c\", )\n",
    "####\n",
    "# model = R_LIGN(DIST_VEC_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt\n",
    "accuracy = []\n",
    "num_of_labels = len(LABELS)\n",
    "\n",
    "opt = th.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "scaler = GradScaler() if AMP_ENABLE else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained Model\n",
    "***_ Replace file name_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('data/model/LIGN_training_model_cool.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "if AMP_ENABLE:\n",
    "    scaler.load_state_dict(checkpoint['scaler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'lign' has no attribute 'train'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-656888df5c25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuperv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABELS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mINIT_NUM_LAB\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINIT_NUM_LAB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_labels\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mretrain_track\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lign' has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "lg.train.superv(model, dataset, LABELS[:INIT_NUM_LAB])\n",
    "\n",
    "for num_labels in range(INIT_NUM_LAB, num_of_labels + 1):\n",
    "\n",
    "    retrain_track = num_labels%30\n",
    "    if retrain_track == 15:\n",
    "        lg.train.unsuperv(model, dataset, opt, \"x\", \"labels\", DIST_VEC_SIZE, LAMBDA, LABELS[:num_labels], (device, scaler), subgraph_size=SUBGRPAH_SIZE)\n",
    "    elif retrain_track == 0:\n",
    "        lg.train.superv(model, dataset, opt, \"x\", \"labels\", DIST_VEC_SIZE, LAMBDA, LABELS[:num_labels], (device, scaler), subgraph_size=SUBGRPAH_SIZE)\n",
    "    \n",
    "    #acc = lg.test.accuracy(model, validate, cluster, LABELS[:num_labels])\n",
    "    accuracy.append()\n",
    "    print(\"Label: {num_labels}/{num_of_labels} | Accuracy: {acc} | Unsurpervised Retraining: {retrain_track}:15 | \" +\n",
    "    \"Surpervised Retraining: {retrain_track}:0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utl.io.json(accuracy, \"data/performance/accuracy/LIGN_training_acc_\"+str(tm_now())+\".json\")\n",
    "## loss\n",
    "\n",
    "check = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": opt.state_dict()\n",
    "}\n",
    "\n",
    "if AMP_ENABLE:\n",
    "    check[\"scaler\"] = scaler.state_dict()\n",
    "\n",
    "th.save(check, \"data/model/LIGN_training_model_\"+str(tm_now())+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## View\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}