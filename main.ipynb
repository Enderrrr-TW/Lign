{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.models as md\n",
    "import lign.utils as utl\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "tm_now = datetime.datetime.now\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "\n",
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/datasets/cifar100_train.lign\")\n",
    "\n",
    "validate = utl.io.cifar_to_lign(\"data/datasets/CIFAR100\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lg.graph.GraphDataset(\"data/datasets/cifar100_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs):\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neighs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "* LAMBDA: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating pairwise loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model initially in the supervised method to learn pairwise mapping\n",
    "* LABELS: list of all the labels that model comes across. Labels can be appended at any time. The order of labels is initially randomized\n",
    "* SUBGRAPH_SIZE: represent the number of nodes processed at once. The models don't have batches. This is the closest thing to it\n",
    "* AMP_ENABLE: to enable mixed precission training\n",
    "* LR: Learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.0001\n",
    "DIST_VEC_SIZE = 3 # 3 was picked so the graph can be drawn in a 3d grid\n",
    "INIT_NUM_LAB = 10\n",
    "LABELS = np.arange(100)\n",
    "SUBGRPAH_SIZE = 200\n",
    "AMP_ENABLE = True\n",
    "LR = 1e-3\n",
    "\n",
    "np.random.shuffle(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Models\n",
    "### LIGN\n",
    "\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIGN_CIFAR(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_cnn, self).__init__()\n",
    "        self.gcn1 = md.layers.GCN(nn.Conv2d(3, 6, 5))\n",
    "        self.gcn2 = md.layers.GCN(nn.Conv2d(6, 16, 5))\n",
    "        self.gcn3 = md.layers.GCN(nn.Linear(16 * 5 * 5, 150))\n",
    "        self.gcn4 = md.layers.GCN(nn.Linear(150, 84))\n",
    "        self.gcn5 = md.layers.GCN(nn.Linear(84, out_feats))\n",
    "        self.pool = md.layers.GCN(nn.MaxPool2d(2, 2))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.pool(F.relu(self.gcn1(g, features)))\n",
    "        x = self.pool(F.relu(self.gcn2(g, x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "        x = F.relu(self.gcn4(g, x))\n",
    "        \n",
    "        return th.tanh(self.gcn5(g, x))\n",
    "\n",
    "model = LIGN_CIFAR(DIST_VEC_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LIGN\n",
    "[R]ecurrent [L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (R-LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.set_data(\"h\", )\n",
    "#dataset.set_data(\"c\", )\n",
    "####\n",
    "# model = R_LIGN(DIST_VEC_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt\n",
    "accuracy = []\n",
    "log = []\n",
    "num_of_labels = len(LABELS)\n",
    "opt = th.optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = GradScaler() if AMP_ENABLE else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('data/models/LIGN_training_cool_time.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "if AMP_ENABLE:\n",
    "    scaler.load_state_dict(checkpoint['scaler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.train.superv(model, dataset, LABELS[:INIT_NUM_LAB])\n",
    "\n",
    "for num_labels in range(INIT_NUM_LAB, num_of_labels + 1):\n",
    "\n",
    "    retrain_track = num_labels%30\n",
    "    if retrain_track == 15:\n",
    "        lg.train.unsuperv(model, dataset, opt, \"x\", \"labels\", DIST_VEC_SIZE, LABELS[:num_labels], LAMBDA, (device, scaler), subgraph_size=SUBGRPAH_SIZE)\n",
    "    elif retrain_track == 0:\n",
    "        lg.train.superv(model, dataset, opt, \"x\", \"labels\", DIST_VEC_SIZE, LABELS[:num_labels], LAMBDA, (device, scaler), subgraph_size=SUBGRPAH_SIZE)\n",
    "    \n",
    "    #acc = lg.test.accuracy(model, validate, cluster, LABELS[:num_labels])\n",
    "    accuracy.append()\n",
    "    log.append(\"Label: {}/{} | Accuracy: {} | Unsurpervised Retraining: {} | Surpervised Retraining: {}\".format(num_labels, num_of_labels, acc, retrain_track == 15, retrain_track == 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tm_now()\n",
    "\n",
    "## Save metrics\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"log\": log\n",
    "}\n",
    "utl.io.json(metrics, \"data/metrics/LIGN_training_\"+str(time)+\".json\")\n",
    "\n",
    "## Save model checkpoint\n",
    "check = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": opt.state_dict()\n",
    "}\n",
    "if AMP_ENABLE:\n",
    "    check[\"scaler\"] = scaler.state_dict()\n",
    "\n",
    "th.save(check, \"data/models/LIGN_training_\"+str(time)+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## View\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}