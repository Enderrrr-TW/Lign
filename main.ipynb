{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGN\n",
    "Graph Induced Lifelong Learning for Spatial-Temporal Data\n",
    "\n",
    "----\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lign as lg\n",
    "import lign.models as md\n",
    "import lign.utils as utl\n",
    "\n",
    "import torch as th\n",
    "import torchvision as tv\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "tm_now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Preprocessing \n",
    "\n",
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"CIFAR\" #<<<<<\n",
    "\n",
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset = utl.load.cifar_to_lign(\"data/datasets/CIFAR100\", transforms = trans)\n",
    "dataset.save(\"data/datasets/cifar100_train.lign\")\n",
    "\n",
    "validate = utl.load.cifar_to_lign(\"data/datasets/CIFAR100\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MNIST\" #<<<<<\n",
    "\n",
    "trans = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = utl.load.mnist_to_lign(\"data/datasets/MNIST\", transforms = trans)\n",
    "dataset.save(\"data/datasets/mnist_train.lign\")\n",
    "\n",
    "validate = utl.load.mnist_to_lign(\"data/datasets/MNIST\", train=False, transforms = trans)\n",
    "validate.save(\"data/datasets/mnist_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"CIFAR\" #<<<<<\n",
    "\n",
    "dataset = lg.graph.GraphDataset(\"data/datasets/cifar100_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/cifar100_test.lign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MNIST\" #<<<<<\n",
    "\n",
    "dataset = lg.graph.GraphDataset(\"data/datasets/mnist_train.lign\")\n",
    "validate = lg.graph.GraphDataset(\"data/datasets/mnist_test.lign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if th.cuda.is_available():\n",
    "    device = th.device(\"cuda\")\n",
    "    th.cuda.empty_cache()\n",
    "else:\n",
    "    device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_neighs_data(neighs): ## adds up neighbors' data before executing post_mod (pre_mod happens before)\n",
    "    out = neighs[0]\n",
    "    for neigh in neighs[1:]:\n",
    "        out = out + neigh\n",
    "    return out\n",
    "\n",
    "class ADDON(nn.Module): ## tempory layer for training\n",
    "    def __init__(self, in_fea, out_fea, device = 'cuda'):\n",
    "        super(ADDON, self).__init__()\n",
    "        self.addon = lg.layers.ADDON(in_fea, out_fea, device=device)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = F.log_softmax(self.addon(g, features), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "* LAMBDA: regulates how much the model relies on difference between the nodes vs the features that lead to their label when calculating pairwise loss\n",
    "* DIST_VEC_SIZE: size of vector representing the mapping of the nodes by the model\n",
    "* INIT_NUM_LAB: number of labels used to training the model initially in the supervised method to learn pairwise mapping\n",
    "* LABELS: list of all the labels that model comes across. Labels can be appended at any time. The order of labels is initially randomized\n",
    "* SUBGRAPH_SIZE: represent the number of nodes processed at once. The models don't have batches. This is the closest thing to it\n",
    "* AMP_ENABLE: toggle to enable mixed precission training\n",
    "* EPOCHS: Loops executed during training\n",
    "* LR: Learning rate\n",
    "* RETRAIN_PER: period between retraining based on number of labels seen. format: (offset, period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 0.1\n",
    "DIST_VEC_SIZE = 128 #128\n",
    "INIT_NUM_LAB = 4\n",
    "LABELS = np.arange(10)\n",
    "SUBGRPAH_SIZE = 500\n",
    "AMP_ENABLE = True\n",
    "EPOCHS = 300\n",
    "LR = 1e-3\n",
    "RETRAIN_PER = {\n",
    "    \"superv\": (6, 3), # (offset, frequency)\n",
    "    #\"semi\": (0, 15)\n",
    "}\n",
    "\n",
    "#np.random.shuffle(LABELS)\n",
    "LABELS = np.array([3, 1, 0, 9, 5, 7, 2, 4, 8, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Models\n",
    "### LIGN\n",
    "\n",
    "[L]ifelong Learning [I]nduced by [G]raph [N]eural Networks Model (LIGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LIGN_MNIST(nn.Module):\n",
    "    def __init__(self, out_feats):\n",
    "        super(LIGN_MNIST, self).__init__()\n",
    "        self.gcn1 = lg.layers.GCN(nn.Conv2d(1, 32, 3, 1))\n",
    "        self.gcn2 = lg.layers.GCN(nn.Conv2d(32, 64, 3, 1))\n",
    "        self.gcn3 = lg.layers.GCN(nn.Linear(9216, out_feats))\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, g, features, save=False):\n",
    "        x = F.relu(self.gcn1(g, features))\n",
    "        if(save):\n",
    "            x_sv = x[:100]\n",
    "            print(x_sv.shape)\n",
    "            for i in range(x_sv.size(0)):\n",
    "                save_image(th.unsqueeze(x_sv[i], 1), \"data/thesis/mid/gcn1/img\" + str(i) + \".png\")\n",
    "\n",
    "        x = F.relu(self.gcn2(g, x))\n",
    "        if(save):\n",
    "            x_sv = x[:100]\n",
    "            for i in range(x_sv.size(0)):\n",
    "                save_image(th.unsqueeze(x_sv[i], 1), \"data/thesis/mid/gcn2/img\" + str(i) + \".png\")\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = th.flatten(self.drop1(x), 1)\n",
    "        x = F.relu(self.gcn3(g, x))\n",
    "        if(save):\n",
    "            x_sv = x[:100]\n",
    "            save_image(th.unsqueeze(th.unsqueeze(x_sv, 1), -1), \"data/thesis/mid/vector output.png\", nrow=100)\n",
    "\n",
    "        return self.drop2(x)\n",
    "\n",
    "model = LIGN_MNIST(DIST_VEC_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt\n",
    "accuracy = []\n",
    "log = []\n",
    "num_of_labels = len(LABELS)\n",
    "opt = th.optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = GradScaler() if AMP_ENABLE else None\n",
    "addon = ADDON(DIST_VEC_SIZE, INIT_NUM_LAB, device).to(device)\n",
    "\n",
    "retrain_superv = lambda x: (x + RETRAIN_PER[\"superv\"][0])%RETRAIN_PER[\"superv\"][1] == 0\n",
    "#retrain_semi = lambda x: (x + RETRAIN_PER[\"semi\"][0])%RETRAIN_PER[\"semi\"][1] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = th.load('data/models/LIGN_training_cool_time.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "opt.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "if AMP_ENABLE:\n",
    "    scaler.load_state_dict(checkpoint['scaler'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = INIT_NUM_LAB + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 32, 26, 26])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "89.46151304922365"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:num_labels], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device, save_img = True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 32, 26, 26])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "95.47653604257378"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:num_labels], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:num_labels], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device, save_img = True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 32, 26, 26])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "98.16951850378034"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "addon.addon.update_size(num_labels)\n",
    "EPOCHS -= int(EPOCHS*0.05)\n",
    "lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:num_labels], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:num_labels], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device, save_img = True)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 1, 0, 9, 5, 7, 2, 4, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "a = [(85.97000483792937, \"4-original\"), (95.47653604257378, \"4-train\"), (78.73060087544768, \"5\"), (98.16951850378034,\"5-train\"), (89.46151304922365, \"6\")]\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:INIT_NUM_LAB], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label: 4/10 -- Accuracy: 86.07% -- Original\n",
      "Label: 4/10 -- Accuracy: 98.86% -- Semisurpervised Retraining: False -- Surpervised Retraining: False\n",
      "Label: 5/10 -- Accuracy: 92.02% -- Semisurpervised Retraining: False -- Surpervised Retraining: False\n",
      "Label: 6/10 -- Accuracy: 97.91% -- Semisurpervised Retraining: False -- Surpervised Retraining: True\n",
      "Label: 7/10 -- Accuracy: 91.1% -- Semisurpervised Retraining: False -- Surpervised Retraining: False\n",
      "Label: 8/10 -- Accuracy: 83.92% -- Semisurpervised Retraining: False -- Surpervised Retraining: False\n",
      "Label: 9/10 -- Accuracy: 95.35% -- Semisurpervised Retraining: False -- Surpervised Retraining: True\n",
      "Label: 10/10 -- Accuracy: 93.88% -- Semisurpervised Retraining: False -- Surpervised Retraining: False\n"
     ]
    }
   ],
   "source": [
    "acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:INIT_NUM_LAB], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device)\n",
    "\n",
    "accuracy.append(acc)\n",
    "log.append(\"Label: {}/{} -- Accuracy: {}% -- Original\".format(INIT_NUM_LAB, num_of_labels, round(acc, 2)))\n",
    "print(log[-1])\n",
    "\n",
    "\n",
    "lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:INIT_NUM_LAB], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "\n",
    "for num_labels in range(INIT_NUM_LAB, num_of_labels + 1):\n",
    "    \"\"\"if retrain_semi(num_labels):\n",
    "        lg.train.semi_superv(model, opt, dataset, \"x\", \"labels\", DIST_VEC_SIZE, LABELS[:num_labels], LAMBDA, (device, scaler), addon = ADDON, subgraph_size=SUBGRPAH_SIZE, epochs=EPOCHS, cluster=(utl.clustering.NN(), 5))\"\"\"\n",
    "\n",
    "    if retrain_superv(num_labels):\n",
    "        addon.addon.update_size(num_labels)\n",
    "        EPOCHS -= int(EPOCHS*0.05)\n",
    "        lg.train.superv(model, opt, dataset, \"x\", \"labels\", LABELS[:num_labels], addon, LAMBDA, (device, scaler), epochs=EPOCHS, subgraph_size=SUBGRPAH_SIZE)\n",
    "    \n",
    "    acc = lg.test.accuracy(model, validate, dataset, \"x\", \"labels\", LABELS[:num_labels], cluster=(utl.clustering.NN(), 5), sv_img = '2d', device=device)\n",
    "\n",
    "    accuracy.append(acc)\n",
    "    log.append(\"Label: {}/{} -- Accuracy: {}% -- Semisurpervised Retraining: {} -- Surpervised Retraining: {}\".format(num_labels, num_of_labels, round(acc, 2), False, retrain_superv(num_labels)))\n",
    "    print(log[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = str(tm_now()).replace(\":\", \"-\").replace(\".\", \"\").replace(\" \", \"_\")\n",
    "filename = \"LIGN_\" + dataset_name + \"_training_\"+time\n",
    "\n",
    "## Save metrics\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"log\": log\n",
    "}\n",
    "utl.io.json(metrics, \"data/metrics/\"+filename+\".json\")\n",
    "\n",
    "## Save hyperparameters\n",
    "para = {\n",
    "    \"LAMBDA\": LAMBDA,\n",
    "    \"DIST_VEC_SIZE\": DIST_VEC_SIZE,\n",
    "    \"INIT_NUM_LAB\": INIT_NUM_LAB,\n",
    "    \"LABELS\": LABELS.tolist(),\n",
    "    \"SUBGRPAH_SIZE\": SUBGRPAH_SIZE,\n",
    "    \"AMP_ENABLE\": AMP_ENABLE,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"LR\": LR,\n",
    "    \"RETRAIN_PER\": RETRAIN_PER,\n",
    "    \"STRUCTURE\": str(model)\n",
    "}\n",
    "\n",
    "utl.io.json(para, \"data/parameters/\"+filename+\".json\")\n",
    "\n",
    "## Save model\n",
    "check = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optimizer\": opt.state_dict()\n",
    "}\n",
    "if AMP_ENABLE:\n",
    "    check[\"scaler\"] = scaler.state_dict()\n",
    "\n",
    "th.save(check, \"data/models/\"+filename+\".pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## View\n",
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(LAMBDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}