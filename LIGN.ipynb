{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import dgl\n",
    "from dgl import function as fn\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#set gpu if available\n",
    "if th.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    #device = th.device(\"cuda\")\n",
    "    device = th.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU not available, CPU used\")\n",
    "    device = th.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operation for neigbors\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "    \n",
    "#gcn layer in network\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.pull(g.nodes())\n",
    "        g.apply_nodes(self.apply_mod)\n",
    "        \n",
    "        return g.ndata.pop('h')\n",
    "    \n",
    "#network\n",
    "class LIGN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(LIGN, self).__init__()\n",
    "        self.gcn1 = GCN(in_feats, 100, F.relu)\n",
    "        self.gcn2 = GCN(100, 30, F.relu)\n",
    "        self.gcn3 = GCN(30, out_feats, th.tanh)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        \n",
    "        return self.gcn3(g, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "\n",
    "def similarity_matrix(x):\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    y = x\n",
    "    y_norm = x_norm.view(1, -1)\n",
    "\n",
    "    dist = x_norm + y_norm - 2.0 * th.mm(x, th.transpose(y, 0, 1))\n",
    "    return dist\n",
    "\n",
    "def same_label(y):\n",
    "    s = y.size(0)\n",
    "    y_expand = y.unsqueeze(0).expand(s, s)\n",
    "    Y = y_expand.eq(y_expand.t())\n",
    "    return Y\n",
    "\n",
    "def my_loss(output, labels):\n",
    "    \"\"\"\n",
    "    if nodes with the same label: x^2\n",
    "    if nodes with different label: 1/(10*x^2)\n",
    "    \"\"\"\n",
    "    sim = similarity_matrix(output)\n",
    "    temp = same_label(labels)\n",
    "    same_l = (temp * sim) / (output.size(0)**2)\n",
    "    same_l_inv = ((temp*(-1) + 1) * sim) / (output.size(0)**2)\n",
    "    \n",
    "    loss = ((th.sum(same_l)**2) + (1/(10*th.sum(same_l_inv)**2)))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\"\"\"def has_2_rand_label(nodes): #return nodes of two unseen labels\n",
    "    rand.shuffle(possible_lab)\n",
    "    \n",
    "    out = (nodes.data['t_label'] == possible_lab[0]).squeeze(1)\n",
    "    out.extend((nodes.data['t_label'] == possible_lab[1]).squeeze(1))\n",
    "    \n",
    "    used_lab.append(possible_lab.pop(0).item())\n",
    "    used_lab.append(possible_lab.pop(1).item())\n",
    "    \n",
    "    return out\"\"\"\n",
    "\n",
    "def has_1_rand_label(nodes): return (nodes.data['t_labels'] == possible_lab[0]).squeeze(0)\n",
    "\n",
    "def filter_knn_label(nodes): return (nodes.data['t_labels'] == curr_used_lab).squeeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = citegrh.load_cora()\n",
    "ds_features = th.FloatTensor(data.features).to(device) #convert to pytorch data type and add to cpu/gpu\n",
    "ds_labels = th.LongTensor(data.labels).to(device)\n",
    "ds_g = data.graph\n",
    "\n",
    "# add self loop for the sum of festures\n",
    "ds_g.remove_edges_from(nx.selfloop_edges(ds_g))\n",
    "ds_g = DGLGraph(ds_g)\n",
    "ds_g.add_edges(ds_g.nodes(), ds_g.nodes())\n",
    "ds_g.ndata['features'] = ds_features\n",
    "ds_g.ndata['t_labels'] = ds_labels #used to filter and train the first two labels, not needed for prediction\n",
    "\n",
    "# to coordinate sending of features over the graph network\n",
    "m_func = fn.copy_src(src='h', out='m')\n",
    "m_reduce_func = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Create Model ############\n",
    "\n",
    "#constant parameters\n",
    "DIST_VEC_SIZE = 10\n",
    "NUMBER_OF_LABELS = 7\n",
    "\n",
    "model = LIGN(ds_features.size()[1], DIST_VEC_SIZE).to(device)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "opt = th.optim.Adam(model.parameters(), lr=1e-3)# only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "train_g = ds_g.subgraph(ds_g.nodes()[:int(len(ds_g) * .80)])#80 percent of all the nodes\n",
    "test_g = ds_g.subgraph(ds_g.nodes()[int(len(ds_g) * .80):]) #20 percent labeled nodes for knn\n",
    "train_g.copy_from_parent()\n",
    "test_g.copy_from_parent()\n",
    "\n",
    "possible_lab = list(range(NUMBER_OF_LABELS))\n",
    "rand.shuffle(possible_lab) #set random order for how labels are added\n",
    "used_lab = []\n",
    "curr_used_lab = 0\n",
    "\n",
    "EPOCH = 50\n",
    "\n",
    "model.train()\n",
    "\n",
    "#############train with 2 labels of 7 labels (uses true label from the dataset), assign vector to each node,\n",
    "            #knn (1 labeled node for each label), test\n",
    "selected_nodes = train_g.filter_nodes(has_1_rand_label) #add two unseen labels\n",
    "used_lab.append(possible_lab.pop(0))\n",
    "selected_nodes = th.cat((train_g.filter_nodes(has_1_rand_label), selected_nodes), -1)\n",
    "used_lab.append(possible_lab.pop(0))\n",
    "\n",
    "c=th.randperm(len(selected_nodes)) #shuffle\n",
    "selected_nodes=selected_nodes[c]\n",
    "\n",
    "#train\n",
    "for epoch in range(EPOCH):\n",
    "    print(\"> \" + str(epoch))\n",
    "    c=th.randperm(len(selected_nodes)) #shuffle\n",
    "    selected_nodes=selected_nodes[c]\n",
    "    epoch_nodes = selected_nodes[:int(len(selected_nodes)*.20)] #selected 20% of random nodes to train with at each epoch\n",
    "    \n",
    "    error = []\n",
    "    for count in range(len(epoch_nodes)):\n",
    "        sub_graph = train_g.subgraph(epoch_nodes[:count])\n",
    "        sub_graph.copy_from_parent()\n",
    "        sub_graph.register_message_func(m_func)\n",
    "        sub_graph.register_reduce_func(m_reduce_func)\n",
    "        \n",
    "        feats = sub_graph.ndata['features']\n",
    "        labs = sub_graph.ndata['t_labels'] #true label\n",
    "        \n",
    "        out = model(sub_graph, feats)\n",
    "        loss = my_loss(out, labs)\n",
    "        error.append(loss.item())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "#knn and assign vector\n",
    "sub_tra_graph = train_g.subgraph(selected_nodes)\n",
    "sub_tra_graph.copy_from_parent()\n",
    "sub_tra_graph.register_message_func(m_func)\n",
    "sub_tra_graph.register_reduce_func(m_reduce_func)\n",
    "\n",
    "##test graph knn\n",
    "out_nodes = th.FloatTensor([])\n",
    "for n in used_lab:\n",
    "    curr_used_lab = n\n",
    "    out_nodes = th.cat((test_g.filter_nodes(has_1_rand_label), out_nodes), -1)\n",
    "\n",
    "c=th.randperm(len(out_nodes)) #shuffle\n",
    "out_nodes=out_nodes[c]\n",
    "\n",
    "sub_tes_graph = test_g.subgraph(out_nodes)\n",
    "sub_tes_graph.copy_from_parent()\n",
    "sub_tes_graph.register_message_func(m_func)\n",
    "sub_tes_graph.register_reduce_func(m_reduce_func)\n",
    "\n",
    "knn.fit(model(sub_tes_graph, sub_tes_graph.ndata['features']), sub_tes_graph.ndata['t_labels'])\n",
    "sub_tra_graph.ndata['p_labels'] = knn.predict(model(sub_tra_graph, sub_tra_graph.ndata['features']))\n",
    "\n",
    "#test\n",
    "print(f\"Accuracy: {metrics.accuracy_score(sub_tra_graph.ndata['t_labels'], sub_tra_graph.ndata['p_labels'])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "\tavg error = 2.849159374212042e-06 \n",
      "\tlast error = 3.274331472624681e-09 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 1: \n",
      "\tavg error = 8.396367201980384e-09 \n",
      "\tlast error = 1.2516924163818999e-09 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 2: \n",
      "\tavg error = 3.1999168450808323e-09 \n",
      "\tlast error = 9.623448704587645e-10 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 3: \n",
      "\tavg error = 1.4447087481560294e-09 \n",
      "\tlast error = 3.491356093121567e-10 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 4: \n",
      "\tavg error = 7.560877813046131e-10 \n",
      "\tlast error = 1.263662063877291e-09 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 5: \n",
      "\tavg error = 4.4562802434009954e-10 \n",
      "\tlast error = 7.072740171309988e-10 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 6: \n",
      "\tavg error = 2.901853388827861e-10 \n",
      "\tlast error = 5.298499139438917e-11 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 7: \n",
      "\tavg error = 2.0170063083032827e-10 \n",
      "\tlast error = 2.8992380718406707e-10 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 8: \n",
      "\tavg error = 1.4668436670473547e-10 \n",
      "\tlast error = 3.8566372317916375e-11 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n",
      "Epoch 9: \n",
      "\tavg error = 1.1203743413544487e-10 \n",
      "\tlast error = 4.5502200098079815e-12 \n",
      "\tavg accuracy = 0.0 \n",
      "\tlast accuracy = 0.0 \n"
     ]
    }
   ],
   "source": [
    "  \n",
    "#training \n",
    "#######################add label, assign vector to each node, knn, test and train (with predicted labels by knn)\n",
    "\n",
    "while len(possible_lab) > 0: #do it for every unseen label\n",
    "    selected_nodes = th.cat((train_g.filter_nodes(has_1_rand_label), selected_nodes), -1) #add unseen new label (change 1 to 2 to add to labels at once)\n",
    "    used_lab.append(possible_lab.pop(0))\n",
    "    c=th.randperm(len(selected_nodes)) #shuffle\n",
    "    selected_nodes=selected_nodes[c]\n",
    "    \n",
    "    #assign vector\n",
    "    #knn\n",
    "    #test\n",
    "    #train\n",
    "    for epoch in range(EPOCH):\n",
    "        c=th.randperm(len(selected_nodes)) #shuffle\n",
    "        selected_nodes=selected_nodes[c]\n",
    "        epoch_nodes = selected_nodes[:int(len(selected_nodes)*.20)] #select 20% of random nodes to train with at each epoch\n",
    "\n",
    "        error = []\n",
    "        for count in range(len(epoch_nodes)):\n",
    "            sub_graph = train_g.subgraph(epoch_nodes[:count])\n",
    "            sub_graph.copy_from_parent()\n",
    "            sub_graph.register_message_func(m_func)\n",
    "            sub_graph.register_reduce_func(m_reduce_func)\n",
    "\n",
    "            feats = sub_graph.ndata['features']\n",
    "            \n",
    "            labs = sub_graph.ndata['t_labels'] #change to predicted label by knn (if label not given) *********\n",
    "\n",
    "            out = model(sub_graph, feats)\n",
    "            loss = my_loss(out, labs)\n",
    "            error.append(loss.item())\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 4, 4, 3, 3, 6, 2, 2, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_g.ndata['t_label'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "list.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
